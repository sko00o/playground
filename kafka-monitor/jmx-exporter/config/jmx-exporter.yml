# reference: https://github.com/prometheus/jmx_exporter/blob/main/example_configs/kafka-2_0_0.yml
---
lowercaseOutputName: true
rules:
  ## Special cases and very specific rules
  # kafka.server:type=FetcherLagMetrics,name=ConsumerLag,clientId=([-.\w]+),topic=([-.\w]+),partition=([0-9]+)
  - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value
    name: kafka_server_$1_$2
    type: GAUGE
    labels:
      clientId: "$3"
      topic: "$4"
      partition: "$5"
  # not found
  - pattern: kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value
    name: kafka_server_$1_$2
    type: GAUGE
    labels:
      clientId: "$3"
      broker: "$4:$5"
  
  # kafka.coordinator.group:type=GroupMetadataManager,name=NumGroups
  # kafka.coordinator.group:type=GroupMetadataManager,name=NumGroupsCompletingRebalance
  # kafka.coordinator.group:type=GroupMetadataManager,name=NumGroupsDead
  # kafka.coordinator.group:type=GroupMetadataManager,name=NumGroupsEmpty
  # kafka.coordinator.group:type=GroupMetadataManager,name=NumGroupsPreparingRebalance
  # kafka.coordinator.group:type=GroupMetadataManager,name=NumGroupsStable
  # kafka.coordinator.group:type=GroupMetadataManager,name=NumOffsets
  # kafka.coordinator.transaction:type=TransactionMarkerChannelManager,name=LogAppendRetryQueueSize
  # kafka.coordinator.transaction:type=TransactionMarkerChannelManager,name=UnknownDestinationQueueSize
  - pattern: kafka.coordinator.(\w+)<type=(.+), name=(.+)><>Value
    name: kafka_coordinator_$1_$2_$3
    type: GAUGE

  ## Generic per-second counters with 0-2 key/value pairs
  # kafka.network:type=RequestMetrics,name=RequestsPerSec,request={Produce|FetchConsumer|FetchFollower},version=([0-9]+)
  # kafka.network:type=RequestMetrics,name=ErrorsPerSec,request=([-.\w]+),error=([-.\w]+)
  - pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*, (.+)=(.+), (.+)=(.+)><>Count
    name: kafka_$1_$2_$3_total
    type: COUNTER
    labels:
      "$4": "$5"
      "$6": "$7"

  # kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name={Produce|Fetch}MessageConversionsPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name=ReplicationBytesInPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name=ReplicationBytesOutPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec,topic=([-.\w]+)
  # kafka.server:type=BrokerTopicMetrics,name=TotalFetchRequestsPerSec,topic=([-.\w]+)
  # kafka.server:type=DelayedFetchMetrics,name=ExpiresPerSec,fetcherType={consumer|follower}
  - pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*, (.+)=(.+)><>Count
    name: kafka_$1_$2_$3_total
    type: COUNTER
    labels:
      "$4": "$5"

  # kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec
  # kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec
  # kafka.server:type=BrokerTopicMetrics,name=BytesRejectedPerSec
  # kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec
  # kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec
  # kafka.server:type=BrokerTopicMetrics,name=FetchMessageConversionsPerSec
  # kafka.server:type=BrokerTopicMetrics,name=InvalidMagicNumberRecordsPerSec
  # kafka.server:type=BrokerTopicMetrics,name=InvalidMessageCrcRecordsPerSec
  # kafka.server:type=BrokerTopicMetrics,name=InvalidOffsetOrSequenceRecordsPerSec
  # kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec
  # kafka.server:type=BrokerTopicMetrics,name=NoKeyCompactedTopicRecordsPerSec
  # kafka.server:type=BrokerTopicMetrics,name=ProduceMessageConversionsPerSec
  # kafka.server:type=BrokerTopicMetrics,name=ReassignmentBytesInPerSec
  # kafka.server:type=BrokerTopicMetrics,name=ReassignmentBytesOutPerSec
  # kafka.server:type=BrokerTopicMetrics,name=ReplicationBytesInPerSec
  # kafka.server:type=BrokerTopicMetrics,name=ReplicationBytesOutPerSec
  # kafka.server:type=BrokerTopicMetrics,name=TotalFetchRequestsPerSec
  # kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec
  # kafka.server:type=ReplicaManager,name=FailedIsrUpdatesPerSec
  # kafka.server:type=ReplicaManager,name=IsrExpandsPerSec
  # kafka.server:type=ReplicaManager,name=IsrShrinksPerSec
  # kafka.server:type=FetchSessionCache,name=IncrementalFetchSessionEvictionsPerSec
  # kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec
  - pattern: kafka.(\w+)<type=(.+), name=(.+)PerSec\w*><>Count
    name: kafka_$1_$2_$3_total
    type: COUNTER

  ## Quota specific rules
  # kafka.server:type={Produce|Fetch},user=([-.\w]+),client-id=([-.\w]+)
  # kafka.server:type=Request,user=([-.\w]+),client-id=([-.\w]+) ## NOTE: not found in jconsole
  - pattern: kafka.server<type=(.+), user=(.+), client-id=(.+)><>([a-z-]+)
    name: kafka_server_quota_$4
    type: GAUGE
    labels:
      resource: "$1"
      user: "$2"
      clientId: "$3"

  # not found
  - pattern: kafka.server<type=(.+), client-id=(.+)><>([a-z-]+)
    name: kafka_server_quota_$3
    type: GAUGE
    labels:
      resource: "$1"
      clientId: "$2"

  # not found
  - pattern: kafka.server<type=(.+), user=(.+)><>([a-z-]+)
    name: kafka_server_quota_$3
    type: GAUGE
    labels:
      resource: "$1"
      user: "$2"

  ## Generic gauges with 0-2 key/value pairs
  # kafka.log:type=Log,name=Size,topic=([-.\w]+),partition=([0-9]+)
  # kafka.log:type=Log,name=NumLogSegments,topic=([-.\w]+),partition=([0-9]+)
  # kafka.log:type=Log,name=LogStartOffset,topic=([-.\w]+),partition=([0-9]+)
  # kafka.log:type=Log,name=LogEndOffset,topic=([-.\w]+),partition=([0-9]+)
  # kafka.cluster:type=Partition,name={AtMinLsr|InSyncReplicasCount|LastStableOffsetLag|ReplicaCount|UnderMinLsr|UnderReplicated},topic=([-.\w]+),partition=([0-9]+)
  - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Value
    name: kafka_$1_$2_$3
    type: GAUGE
    labels:
      "$4": "$5"
      "$6": "$7"

  # kafka.server:type=DelayedOperationPurgatory,name={NumDelayedOperations|PurgatorySize},delayedOperation={AlterAcls|DeleteRecords|ElectLeader|Fetch|Heartbeat|Produce|Rebalance}
  # kafka.controller:type=ControllerChannelManager,name=RequestRateAndQueueTimeMs,brokerId=([0-9]+)
  # kafka.log:type=LogManager,name=LogDirectoryOffline,logDirectory=(.+)
  # kafka.log:type=LogCleanerManager,name={uncleanable-bytes|uncleanable-partitions-count},logDirectory=(.+)
  # kafka.network:type=Processor,name=IdlePercent,networkProcessor=([0-9]+)
  # kafka.network:type=RequestChannel,name=ResponseQueueSize,processor=([0-9]+)
  # kafka.network:type=Processor,name=IdlePercent,networkProcessor=([0-9]+)
  # kafka.server:type=ReplicaAlterLogDirsManager,name=DeadThreadCount,clientId=ReplicaAlterLogDirs
  # kafka.server:type=ReplicaAlterLogDirsManager,name=FailedPartitionsCount,clientId=ReplicaAlterLogDirs
  # kafka.server:type=ReplicaAlterLogDirsManager,name=MaxLag,clientId=ReplicaAlterLogDirs
  # kafka.server:type=ReplicaAlterLogDirsManager,name=MinFetchRate,clientId=ReplicaAlterLogDirs
  # kafka.server:type=ReplicaFetcherManager,name=DeadThreadCount,clientId=Replica
  # kafka.server:type=ReplicaFetcherManager,name=FailedPartitionsCount,clientId=Replica
  # kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica
  # kafka.server:type=ReplicaFetcherManager,name=MinFetchRate,clientId=Replica
  - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+)><>Value
    name: kafka_$1_$2_$3
    type: GAUGE
    labels:
      "$4": "$5"

  # kafka.controller:type=ControllerEventManager,name=EventQueueSize
  # kafka.controller:type=ControllerEventManager,name=EventQueueTimeMs
  # kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs
  # kafka.controller:type=KafkaController,name=ActiveControllerCount
  # kafka.controller:type=KafkaController,name=TopicsToDeleteCount
  # kafka.controller:type=KafkaController,name=ReplicasToDeleteCount
  # kafka.controller:type=KafkaController,name=TopicsIneligibleToDeleteCount
  # kafka.controller:type=KafkaController,name=ReplicasIneligibleToDeleteCount
  # kafka.server:type=ReplicaManager,name=AtMinIsrPartitionCount
  # kafka.server:type=ReplicaManager,name=LeaderCount
  # kafka.server:type=ReplicaManager,name=OfflineReplicaCount
  # kafka.server:type=ReplicaManager,name=PartitionCount
  # kafka.server:type=ReplicaManager,name=PartitionsWithLateTransactionsCount
  # kafka.server:type=ReplicaManager,name=ReassigningPartitions
  # kafka.server:type=ReplicaManager,name=UnderMinIsrPartitionCount
  # kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions
  # kafka.server:type=ReplicaManager,name=ProducerIdCount # not fount
  # kafka.server:type=socket-server-metrics,listener=[SASL_PLAINTEXT|SASL_SSL],networkProcessor=<#>,name=expired-connections-killed-count
  # kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent
  # kafka.server:type=ZooKeeperClientMetrics,name=ZooKeeperRequestLatencyMs
  # kafka.server:type=SessionExpireListener,name=SessionState
  # kafka.server:type=group-coordinator-metrics,name=partition-load-time-max
  # kafka.server:type=group-coordinator-metrics,name=partition-load-time-avg
  # kafka.server:type=transaction-coordinator-metrics,name=partition-load-time-max
  # kafka.server:type=transaction-coordinator-metrics,name=partition-load-time-avg
  # kafka.server:type=GroupMetadataManager,name=NumOffsets
  # kafka.server:type=GroupMetadataManager,name=NumGroups
  # kafka.server:type=GroupMetadataManager,name=NumGroups[PreparingRebalance,CompletingRebalance,Empty,Stable,Dead]
  # kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent
  # kafka.network:type=SocketServer,name=ExpiredConnectionsKilledCount
  # kafka.network:type=SocketServer,name={MemoryPoolUsed|MemoryPoolAvailable}
  # kafka.network:type=RequestChannel,name=RequestQueueSize
  # kafka.network:type=RequestChannel,name=ResponseQueueSize
  # kafka.log:type=LogManager,name=OfflineLogDirectoryCount
  # kafka.log:type=LogCleaner,name={DeadThreadCount|cleaner-recopy-percent|max-buffer-utilization-percent|max-clean-time-secs|max-compaction-delay-secs}
  # kafka.log:type=LogCleanerManager,name={max-dirty-percent|time-since-last-run-ms}
  # kafka.server:type=FetchSessionCache,name=NumIncrementalFetchPartitionsCached
  # kafka.server:type=FetchSessionCache,name=NumIncrementalFetchSessions
  # kafka.server:type=KafkaServer,name={BrokerState|ClusterId|linux-disk-read-bytes|linux-disk-write-bytes|yammer-metrics-count}
  - pattern: kafka.(\w+)<type=(.+), name=(.+)><>Value
    name: kafka_$1_$2_$3
    type: GAUGE

  ## Emulate Prometheus 'Summary' metrics for the exported 'Histogram's.
  ##
  ## Note that these are missing the '_sum' metric!
  - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>Count
    name: kafka_$1_$2_$3_count
    type: COUNTER
    labels:
      "$4": "$5"
      "$6": "$7"
  - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*), (.+)=(.+)><>(\d+)thPercentile
    name: kafka_$1_$2_$3
    type: GAUGE
    labels:
      "$4": "$5"
      "$6": "$7"
      quantile: "0.$8"

  # kafka.network:type=RequestMetrics,name=LocalTimeMs,request={Produce|FetchConsumer|FetchFollower}
  # kafka.network:type=RequestMetrics,name=MessageConversionsTimeMs,request={Produce|Fetch}
  # kafka.network:type=RequestMetrics,name=RemoteTimeMs,request={Produce|FetchConsumer|FetchFollower}
  # kafka.network:type=RequestMetrics,name=RequestBytes,request=([-.\w]+)
  # kafka.network:type=RequestMetrics,name=RequestQueueTimeMs,request={Produce|FetchConsumer|FetchFollower}
  # kafka.network:type=RequestMetrics,name=ResponseQueueTimeMs,request={Produce|FetchConsumer|FetchFollower}
  # kafka.network:type=RequestMetrics,name=ResponseSendTimeMs,request={Produce|FetchConsumer|FetchFollower}
  # kafka.network:type=RequestMetrics,name=TemporaryMemoryBytes,request={Produce|Fetch}
  # kafka.network:type=RequestMetrics,name=ThrottleTimeMs,request=([-.\w]+)
  # kafka.network:type=RequestMetrics,name=TotalTimeMs,request={Produce|FetchConsumer|FetchFollower}
  - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.+)><>Count
    name: kafka_$1_$2_$3_count
    type: COUNTER
    labels:
      "$4": "$5"
  - pattern: kafka.(\w+)<type=(.+), name=(.+), (.+)=(.*)><>(\d+)thPercentile
    name: kafka_$1_$2_$3
    type: GAUGE
    labels:
      "$4": "$5"
      quantile: "0.$6"

  # kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs
  # kafka.utils:type=Throttler,name=cleaner-io
  # kafka.server:type=BrokerMetadataListener,name={MetadataBatchProcessingTimeUs|MetadataBatchSizes}
  # kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent
  - pattern: kafka.(\w+)<type=(.+), name=(.+)><>Count
    name: kafka_$1_$2_$3_count
    type: COUNTER
  - pattern: kafka.(\w+)<type=(.+), name=(.+)><>(\d+)thPercentile
    name: kafka_$1_$2_$3
    type: GAUGE
    labels:
      quantile: "0.$4"

  ## Generic gauges for MeanRate Percent
  ## Ex) kafka.server<type=KafkaRequestHandlerPool, name=RequestHandlerAvgIdlePercent><>MeanRate
  # kafka.network:type=Acceptor,name=AcceptorBlockedPercent,listener={CONTROLLER|PLAINTEXT}
  - pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*><>MeanRate
    name: kafka_$1_$2_$3_percent
    type: GAUGE
  - pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*><>Value
    name: kafka_$1_$2_$3_percent
    type: GAUGE
  - pattern: kafka.(\w+)<type=(.+), name=(.+)Percent\w*, (.+)=(.+)><>Value
    name: kafka_$1_$2_$3_percent
    type: GAUGE
    labels:
      "$4": "$5"

  ## pattern input:
  ## domain<beanpropertyName1=beanPropertyValue1, beanpropertyName2=beanPropertyValue2, ...><key1, key2, ...>attrName: value
  ## default name:
  ## domain_beanPropertyValue1_key1_key2_...keyN_attrName{beanpropertyName2="beanPropertyValue2", ...}: value
  # kafka.server:type=ControllerMutation<>queue-size
  # kafka.server:type=ControllerServer,name=(.+)
  # kafka.server:type=Fetch<>queue-size
  # kafka.server:type=Produce<>queue-size
  # kafka.server:type=Request<>exempt-request-time
  # kafka.server:type=Request<>queue-size
  # kafka.server:type=alterPartition-metrics,BrokerId=(\d+)<>(.+)
  # kafka.server:type=app-info<>(.+)
  # kafka.server:type=app-info,id=(\d+)<>(.+)
  # kafka.server:type=broker-metadata-metrics<>(.+)
  # kafka.server:type=forwarding-metrics,BrokerId=(\d+)<>(.+)
  # kafka.server:type=group-coordinator-metrics<>(.+)
  # kafka.server:type=heartbeat-metrics,BrokerId=(\d+)<>(.+)
  # kafka.server:type=kafka-metrics-count<>count
  # kafka.server:type=raft-channel-metrics<>(.+)
  # kafka.server:type=raft-metrics<>(.+)
  # kafka.server:type=socket-server-metrics<>(.+)
  # kafka.server:type=socket-server-metrics,listener=(\w+),networkProcessor=(\d+)<>(.+)
  # kafka.server:type=socket-server-metrics,clientSoftwareName=(\w+),clientSoftwareVersion=3.4.1,listener=(\w+),networkProcessor=(\d+)<>connections
  # kafka.server:type=transaction-coordinator-metrics<>(.+)
  # kafka.server:type=txn-marker-channel-metrics<>(.+)
  # - pattern: ".*"
